import csv
import time
import warnings
import xml.etree.ElementTree as ET

import requests
import urllib3

# å¿½ç•¥InsecureRequestWarningè­¦å‘Š
warnings.filterwarnings("ignore", category=urllib3.exceptions.InsecureRequestWarning)

# ç”¨æ¥ç»Ÿè®¡æ‰€æœ‰keyçš„åˆ—è¡¨
totoal_keys = []


# è·å–å­˜å‚¨æ¡¶é¡µé¢é»˜è®¤æ˜¾ç¤ºæ¡æ•°max-keys,é»˜è®¤æœ€å¤§ä¸è¶…è¿‡1000
def get_info(url):
    response = requests.get(url, verify=False)
    # è§£æXMLå†…å®¹
    xml_content = response.content
    # è§£æXML
    root = ET.fromstring(xml_content)
    maxkey = root.findtext(f".//MaxKeys")
    nextmarker = root.find(f".//NextMarker")
    xpath_expr = ".//Contents"
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å‘½åç©ºé—´ï¼Œå­˜åœ¨å‘½åç©ºé—´çš„ç´¢å¼•å†™æ³•éœ€è¦æ”¹å˜
    has_namespace = root.tag.startswith("{")
    if has_namespace:
        # è·å–å‘½åç©ºé—´
        namespace = root.tag.split('}')[0].strip('{')
        xpath_expr = f".//{{{namespace}}}Contents"
        maxkey = root.findtext(f".//{{{namespace}}}MaxKeys")
        nextmarker = root.find(f".//{{{namespace}}}NextMarker")
    # è·å–æ‰€æœ‰å­æ ‡ç­¾çš„åç§°
    child_tags = set()
    for contents_element in root.findall(xpath_expr):
        for child_element in contents_element:
            if has_namespace:
                child_tags.add(child_element.tag.replace(f"{{{namespace}}}", ""))
            else:
                child_tags.add(child_element.tag)
    # åˆ›å»ºcsvæ–‡ä»¶å†™å…¥è¡¨å¤´ä¹Ÿå°±æ˜¯å„åˆ—åç§°
    filename = write_csv_header(child_tags)
    # è¿”å›PageSizeã€ä¸‹ä¸€é¡µç´¢å¼•ã€åˆ›å»ºçš„CSVæ–‡ä»¶åç§°ã€ä»¥åŠåˆ—åé›†åˆ
    return maxkey, nextmarker, filename, child_tags


def getdata(baseurl, max_keys, csv_filename, child_tags, marker='', page=0):
    if int(max_keys) < 1000:
        max_keys = 1000
    baseurl = baseurl
    url = baseurl + f'?max-keys={max_keys}&marker={marker}'
    response = requests.get(url, verify=False)
    xml_content = response.content
    root = ET.fromstring(xml_content)
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å‘½åç©ºé—´
    namespace = ''
    xpath_expr = ".//Contents"
    nextmarker = root.findtext(f".//NextMarker")
    has_namespace = root.tag.startswith("{")
    if has_namespace:
        # è·å–å‘½åç©ºé—´
        namespace = root.tag.split('}')[0].strip('{')
        xpath_expr = f".//{{{namespace}}}Contents"
        nextmarker = root.findtext(f".//{{{namespace}}}NextMarker")
    datas = root.findall(xpath_expr)
    # å†™å…¥æ•°æ®
    nums, is_repeate, repeate_nums, total_nums = write_csv_content(csv_filename, datas, has_namespace, namespace,
                                                                   child_tags)
    page += 1
    print(f"[+] ç¬¬{page}é¡µæ£€æµ‹åˆ°{nums}æ¡æ•°æ®,å…±è®¡å‘ç°{total_nums}ä¸ªæ–‡ä»¶")
    # æ˜¯å¦å­˜åœ¨nextmarkerå­˜åœ¨åˆ™è¯´æ˜è¿˜æœ‰ä¸‹ä¸€é¡µéœ€è¦è¿­ä»£è¿›è¡Œéå†ï¼Œä¸å­˜åœ¨åˆ™è¯´æ˜ä»¥åŠéå†å®Œæˆé€€å‡º
    if nextmarker is None or is_repeate == 1:
        print(f"[âˆš] æ•°æ®ç»“æœå·²å†™å…¥æ–‡ä»¶ï¼š{csv_filename}ï¼Œè¯·æŸ¥çœ‹ğŸ˜€")
        return
    getdata(baseurl, max_keys, csv_filename, child_tags, nextmarker, page)


def write_csv_header(child_tags):
    # è·å–å½“å‰æ—¶é—´æˆ³
    timestamp = int(time.time())
    # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    timestamp_str = str(timestamp)
    # åˆ›å»ºCSVæ–‡ä»¶å¹¶å†™å…¥æ•°æ®
    csv_filename = f'xml_data{timestamp_str}.csv'
    with open(csv_filename, 'w', newline='') as csv_file:
        # å†™å…¥è¡¨å¤´ï¼Œå¦å¤–å¢åŠ å®Œæ•´çš„urlå’Œæ–‡ä»¶ç±»å‹åˆ—
        writer = csv.writer(csv_file)
        list_tags = list(child_tags)
        list_tags.append("url")
        list_tags.append("filetype")
        writer.writerow(list_tags)
        return csv_filename


def write_csv_content(csv_filename, datas, has_namespace, namespace, child_tags):
    # æå–æ•°æ®å¹¶å†™å…¥CSVæ–‡ä»¶
    with open(csv_filename, 'a', newline='') as csv_file:
        nums = 0
        repeate_nums = 0
        is_repeate = 0
        # å†™å…¥æ•°æ®
        for contents_element in datas:
            if has_namespace:
                row = [contents_element.findtext(f"{{{namespace}}}{tag}") for tag in child_tags]
                key = contents_element.findtext(f"{{{namespace}}}Key")
            else:
                row = [contents_element.findtext(tag) for tag in child_tags]
                key = contents_element.findtext(f"Key")
            if str(key) not in totoal_keys:
                nums += 1
                totoal_keys.append(key)
                url = str(baseUrl) + str(key)
                parts = str(key).split(".")
                if len(parts) > 1:
                    # å¦‚æœåˆ†å‰²åçš„åˆ—è¡¨é•¿åº¦å¤§äº1ï¼Œè¯´æ˜å­˜åœ¨æ–‡ä»¶åç¼€å
                    file_extension = parts[-1]
                else:
                    # å¦åˆ™ï¼Œæ–‡ä»¶åç¼€åä¸å­˜åœ¨
                    file_extension = ""
                row.append(url)
                row.append(file_extension)
                writer = csv.writer(csv_file)
                writer.writerow(row)
            else:
                repeate_nums += 1
        if repeate_nums > 2:
            is_repeate = 1

        return nums, is_repeate, repeate_nums, len(totoal_keys)


if __name__ == '__main__':
    # å‘é€HTTPè¯·æ±‚è·å–å“åº”
    url = input("[*] è¯·è¾“å…¥å­˜å‚¨æ¡¶éå†urlï¼š").strip()
    baseUrl = input("[*] è¯·è¾“å…¥å­˜å‚¨æ¡¶æ ¹è·¯å¾„(ä¸è¾“å…¥åˆ™å’Œä¸Šè¿°urlä¿æŒä¸€è‡´)ï¼š").strip()
    if baseUrl == '':
        baseUrl = url
    if not baseUrl.endswith('/'):
        baseUrl += '/'
    # è·å–å­˜å‚¨æ¡¶åŸºæœ¬ä¿¡æ¯åŒ…æ‹¬é»˜è®¤çš„PageSizeã€ä¸‹ä¸€é¡µç´¢å¼•ï¼ŒåŒæ—¶åˆ›å»ºcsvæ–‡ä»¶æ ¹æ®å­—æ®µå†™è¡¨å¤´
    try:
        maxkey, nextmarker, csv_filename, child_tags = get_info(url)
        if len(child_tags) != 0:
            print("[+] xmlæ•°æ®æå–æˆåŠŸï¼âœ¨")
            # æœªæŒ‡å®šmaxkeyåˆ™é»˜è®¤1000
            if maxkey == None:
                maxkey = 1000
            print(f"[o] è¯¥å­˜å‚¨æ¡¶é»˜è®¤æ¯é¡µæ˜¾ç¤º{maxkey}æ¡æ•°æ®")
            if nextmarker == None:
                print("[-] è¯¥å­˜å‚¨æ¡¶ä¸æ”¯æŒWebç¿»é¡µéå†ğŸ˜¢")
            else:
                print("[+] è¯¥å­˜å‚¨æ¡¶æ”¯æŒéå†,æ­£åœ¨è·å–æ–‡ä»¶åŠæ•°é‡ğŸ˜€")
            getdata(url, max_keys=maxkey, child_tags=child_tags, csv_filename=csv_filename)
        else:
            print("[-] è¯¥å­˜å‚¨æ¡¶ä¸æ”¯æŒéå†,æˆ–æ£€æŸ¥ç½‘å€æ˜¯å¦æœ‰è¯¯ï¼")
    except Exception as e:
        print(e)
        print("[-] XMLè§£ææœ‰è¯¯ï¼Œæ— æ³•éå†ğŸ˜¢")
